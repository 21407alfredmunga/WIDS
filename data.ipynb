{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Data Loading and Initial Inspection\n",
    "# Training data\n",
    "train_categorical = pd.read_excel(\"widsdatathon2025/TRAIN_NEW/TRAIN_CATEGORICAL_METADATA_new.xlsx\")\n",
    "train_quantitative = pd.read_excel(\"widsdatathon2025/TRAIN_NEW/TRAIN_QUANTITATIVE_METADATA_new.xlsx\")\n",
    "train_connectome = pd.read_csv(\"widsdatathon2025/TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\")\n",
    "train_solutions = pd.read_excel(\"widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\")\n",
    "\n",
    "# Test data\n",
    "test_categorical = pd.read_excel(\"widsdatathon2025/TEST/TEST_CATEGORICAL.xlsx\")\n",
    "test_quantitative = pd.read_excel(\"widsdatathon2025/TEST/TEST_QUANTITATIVE_METADATA.xlsx\")\n",
    "test_connectome = pd.read_csv(\"widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "# Check for matching participant IDs\n",
    "def check_and_merge_data(cat_df, quant_df, conn_df, solutions_df=None):\n",
    "    # Ensure participant_id is the index\n",
    "    cat_df = cat_df.set_index('participant_id') if 'participant_id' in cat_df.columns else cat_df\n",
    "    quant_df = quant_df.set_index('participant_id') if 'participant_id' in quant_df.columns else quant_df\n",
    "    conn_df = conn_df.set_index('participant_id') if 'participant_id' in conn_df.columns else conn_df\n",
    "    \n",
    "    # Find common participant IDs\n",
    "    common_ids = set(cat_df.index).intersection(set(quant_df.index)).intersection(set(conn_df.index))\n",
    "    \n",
    "    if solutions_df is not None:\n",
    "        solutions_df = solutions_df.set_index('participant_id') if 'participant_id' in solutions_df.columns else solutions_df\n",
    "        common_ids = common_ids.intersection(set(solutions_df.index))\n",
    "        \n",
    "    print(f\"Found {len(common_ids)} common participant IDs\")\n",
    "    \n",
    "    # Filter datasets to common IDs\n",
    "    cat_df = cat_df.loc[common_ids]\n",
    "    quant_df = quant_df.loc[common_ids]\n",
    "    conn_df = conn_df.loc[common_ids]\n",
    "    \n",
    "    # Merge all data\n",
    "    merged_df = pd.concat([cat_df, quant_df, conn_df], axis=1)\n",
    "    \n",
    "    if solutions_df is not None:\n",
    "        solutions_df = solutions_df.loc[common_ids]\n",
    "        return merged_df, solutions_df\n",
    "    else:\n",
    "        return merged_df\n",
    "\n",
    "# Merge training data\n",
    "train_data, train_targets = check_and_merge_data(\n",
    "    train_categorical, train_quantitative, train_connectome, train_solutions\n",
    ")\n",
    "\n",
    "# Merge test data\n",
    "test_data = check_and_merge_data(\n",
    "    test_categorical, test_quantitative, test_connectome\n",
    ")\n",
    "\n",
    "# Extract target variables\n",
    "y_adhd = train_targets['ADHD_Outcome']\n",
    "y_sex = train_targets['Sex_F']\n",
    "\n",
    "# 3. Feature Engineering\n",
    "\n",
    "# Create combined stratification column\n",
    "stratify_col = y_adhd.astype(str) + '_' + y_sex.astype(str)\n",
    "\n",
    "# Function to extract features from connectome data\n",
    "def create_connectome_features(connectome_df):\n",
    "    # Identify connectivity columns\n",
    "    conn_cols = [col for col in connectome_df.columns if col.startswith('roi')]\n",
    "    \n",
    "    # Basic statistics\n",
    "    conn_features = pd.DataFrame(index=connectome_df.index)\n",
    "    conn_features['mean_connectivity'] = connectome_df[conn_cols].mean(axis=1)\n",
    "    conn_features['std_connectivity'] = connectome_df[conn_cols].std(axis=1)\n",
    "    conn_features['max_connectivity'] = connectome_df[conn_cols].max(axis=1)\n",
    "    conn_features['min_connectivity'] = connectome_df[conn_cols].min(axis=1)\n",
    "    \n",
    "    # Extract regions from column names and aggregate by region\n",
    "    regions = set()\n",
    "    for col in conn_cols:\n",
    "        parts = col.split('_')\n",
    "        if len(parts) >= 3:\n",
    "            regions.add(parts[1])\n",
    "            regions.add(parts[2])\n",
    "    \n",
    "    # Create region-specific features\n",
    "    for region in list(regions)[:30]:  # Limit to prevent feature explosion\n",
    "        region_cols = [col for col in conn_cols if f'_{region}_' in col or f'_{region}' == col[-len(region)-1:]]\n",
    "        if region_cols:\n",
    "            conn_features[f'region_{region}_mean'] = connectome_df[region_cols].mean(axis=1)\n",
    "            conn_features[f'region_{region}_std'] = connectome_df[region_cols].std(axis=1)\n",
    "    \n",
    "    # Create graph metrics\n",
    "    # Calculate degree (number of strong connections)\n",
    "    threshold = 0.5  # Arbitrary threshold for demonstration\n",
    "    strong_connections = (connectome_df[conn_cols] > threshold).sum(axis=1)\n",
    "    conn_features['degree'] = strong_connections\n",
    "    \n",
    "    return conn_features\n",
    "\n",
    "# Apply feature engineering\n",
    "train_conn_features = create_connectome_features(train_data)\n",
    "test_conn_features = create_connectome_features(test_data)\n",
    "\n",
    "# Split categorical and numerical features\n",
    "cat_features = train_data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_features = train_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove any target columns that might be in the features\n",
    "num_features = [col for col in num_features if col not in ['ADHD_Outcome', 'Sex_F']]\n",
    "\n",
    "# Combine engineered features with original data\n",
    "train_data = pd.concat([train_data, train_conn_features], axis=1)\n",
    "test_data = pd.concat([test_data, test_conn_features], axis=1)\n",
    "\n",
    "# 4. Create preprocessing pipeline\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, num_features),\n",
    "        ('cat', categorical_transformer, cat_features)\n",
    "    ],\n",
    "    remainder='drop'  # Drop columns not specified\n",
    ")\n",
    "\n",
    "# 5. Model Development and Hyperparameter Tuning\n",
    "# Split data for validation\n",
    "X_train, X_val, y_adhd_train, y_adhd_val, y_sex_train, y_sex_val = train_test_split(\n",
    "    train_data, y_adhd, y_sex, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=stratify_col\n",
    ")\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(test_data)\n",
    "\n",
    "# Apply SMOTE separately for sex and ADHD prediction\n",
    "smote_sex = SMOTE(random_state=42)\n",
    "X_train_sex_resampled, y_sex_train_resampled = smote_sex.fit_resample(X_train_processed, y_sex_train)\n",
    "\n",
    "smote_adhd = SMOTE(random_state=42)\n",
    "X_train_adhd_resampled, y_adhd_train_resampled = smote_adhd.fit_resample(X_train_processed, y_adhd_train)\n",
    "\n",
    "# Define optimization function for sex model\n",
    "def optimize_sex_model(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'f1',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 5.0)\n",
    "    }\n",
    "    \n",
    "    # Create model\n",
    "    model = lgb.LGBMClassifier(**params, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_sex_resampled, y_sex_train_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    preds = model.predict(X_val_processed)\n",
    "    f1 = f1_score(y_sex_val, preds)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "# Define optimization function for ADHD model\n",
    "def optimize_adhd_model(trial):\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 3.0)\n",
    "    }\n",
    "    \n",
    "    # Create model\n",
    "    model = xgb.XGBClassifier(**params, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_adhd_resampled, y_adhd_train_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    preds = model.predict(X_val_processed)\n",
    "    f1 = f1_score(y_adhd_val, preds)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "sex_study = optuna.create_study(direction='maximize')\n",
    "sex_study.optimize(optimize_sex_model, n_trials=20)\n",
    "\n",
    "adhd_study = optuna.create_study(direction='maximize')\n",
    "adhd_study.optimize(optimize_adhd_model, n_trials=20)\n",
    "\n",
    "# Train final models with best parameters\n",
    "best_sex_params = sex_study.best_params\n",
    "best_adhd_params = adhd_study.best_params\n",
    "\n",
    "print(\"Best Sex Model Parameters:\")\n",
    "print(best_sex_params)\n",
    "print(\"\\nBest ADHD Model Parameters:\")\n",
    "print(best_adhd_params)\n",
    "\n",
    "# Train final sex model\n",
    "sex_model = lgb.LGBMClassifier(**best_sex_params, random_state=42)\n",
    "sex_model.fit(X_train_sex_resampled, y_sex_train_resampled)\n",
    "\n",
    "# Train final ADHD model\n",
    "adhd_model = xgb.XGBClassifier(**best_adhd_params, random_state=42)\n",
    "adhd_model.fit(X_train_adhd_resampled, y_adhd_train_resampled)\n",
    "\n",
    "# 6. Create specialized female ADHD model\n",
    "female_indices = (y_sex_train == 1)\n",
    "X_female_train = X_train_processed[female_indices]\n",
    "y_female_adhd_train = y_adhd_train[female_indices]\n",
    "\n",
    "# Apply SMOTE for balance\n",
    "smote_female = SMOTE(random_state=42)\n",
    "X_female_train_resampled, y_female_adhd_train_resampled = smote_female.fit_resample(X_female_train, y_female_adhd_train)\n",
    "\n",
    "# Train specialized model\n",
    "female_adhd_model = xgb.XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    min_child_weight=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=2.0,\n",
    "    random_state=42\n",
    ")\n",
    "female_adhd_model.fit(X_female_train_resampled, y_female_adhd_train_resampled)\n",
    "\n",
    "# 7. Create stacked ensemble model\n",
    "def create_ensemble():\n",
    "    # First level models\n",
    "    estimators = [\n",
    "        ('xgb', xgb.XGBClassifier(random_state=42)),\n",
    "        ('lgb', lgb.LGBMClassifier(random_state=42)),\n",
    "        ('xgb_tuned', xgb.XGBClassifier(**best_adhd_params, random_state=42))\n",
    "    ]\n",
    "    \n",
    "    # Final model\n",
    "    final_estimator = xgb.XGBClassifier(learning_rate=0.1, random_state=42)\n",
    "    \n",
    "    # Create stacking ensemble\n",
    "    stacked_model = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=final_estimator,\n",
    "        cv=5,\n",
    "        stack_method='predict_proba'\n",
    "    )\n",
    "    \n",
    "    return stacked_model\n",
    "\n",
    "# Train ensemble models\n",
    "adhd_ensemble = create_ensemble()\n",
    "adhd_ensemble.fit(X_train_adhd_resampled, y_adhd_train_resampled)\n",
    "\n",
    "sex_ensemble = create_ensemble()\n",
    "sex_ensemble.fit(X_train_sex_resampled, y_sex_train_resampled)\n",
    "\n",
    "# 8. Prediction and threshold optimization\n",
    "# Make probability predictions\n",
    "sex_val_proba = sex_model.predict_proba(X_val_processed)[:, 1]\n",
    "adhd_val_proba = adhd_model.predict_proba(X_val_processed)[:, 1]\n",
    "\n",
    "# Also get predictions from ensembles\n",
    "sex_ensemble_proba = sex_ensemble.predict_proba(X_val_processed)[:, 1]\n",
    "adhd_ensemble_proba = adhd_ensemble.predict_proba(X_val_processed)[:, 1]\n",
    "\n",
    "# For females, blend with specialized model predictions\n",
    "sex_val_preds = (sex_val_proba >= 0.5).astype(int)\n",
    "female_val_indices = np.where(sex_val_preds == 1)[0]\n",
    "\n",
    "if len(female_val_indices) > 0:\n",
    "    female_val_subset = X_val_processed[female_val_indices]\n",
    "    female_adhd_proba = female_adhd_model.predict_proba(female_val_subset)[:, 1]\n",
    "    \n",
    "    # Blend predictions for females (70% specialized, 30% general)\n",
    "    adhd_val_proba_blended = adhd_val_proba.copy()\n",
    "    adhd_val_proba_blended[female_val_indices] = 0.3 * adhd_val_proba[female_val_indices] + 0.7 * female_adhd_proba\n",
    "\n",
    "# Optimize thresholds\n",
    "def find_optimal_threshold(y_true, y_proba):\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    for threshold in np.arange(0.1, 0.9, 0.05):\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "        current_f1 = f1_score(y_true, y_pred)\n",
    "        \n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# Find optimal thresholds\n",
    "sex_threshold, sex_best_f1 = find_optimal_threshold(y_sex_val, sex_val_proba)\n",
    "adhd_threshold, adhd_best_f1 = find_optimal_threshold(y_adhd_val, adhd_val_proba_blended)\n",
    "\n",
    "print(f\"Optimal Sex Threshold: {sex_threshold:.4f}, F1: {sex_best_f1:.4f}\")\n",
    "print(f\"Optimal ADHD Threshold: {adhd_threshold:.4f}, F1: {adhd_best_f1:.4f}\")\n",
    "\n",
    "# Create final blended predictions\n",
    "final_sex_val_proba = 0.6 * sex_val_proba + 0.4 * sex_ensemble_proba\n",
    "final_adhd_val_proba = 0.5 * adhd_val_proba_blended + 0.5 * adhd_ensemble_proba\n",
    "\n",
    "final_sex_val_preds = (final_sex_val_proba >= sex_threshold).astype(int)\n",
    "final_adhd_val_preds = (final_adhd_val_proba >= adhd_threshold).astype(int)\n",
    "\n",
    "# Evaluate final blended model\n",
    "sex_final_f1 = f1_score(y_sex_val, final_sex_val_preds)\n",
    "adhd_final_f1 = f1_score(y_adhd_val, final_adhd_val_preds)\n",
    "\n",
    "print(f\"Final Sex F1: {sex_final_f1:.4f}\")\n",
    "print(f\"Final ADHD F1: {adhd_final_f1:.4f}\")\n",
    "\n",
    "# Calculate overall score (average of both F1 scores)\n",
    "overall_f1 = (sex_final_f1 + adhd_final_f1) / 2\n",
    "print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
    "\n",
    "# 9. Apply to test set and generate submission\n",
    "# Make predictions on test data\n",
    "sex_test_proba = sex_model.predict_proba(X_test_processed)[:, 1]\n",
    "adhd_test_proba = adhd_model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Also get predictions from ensembles\n",
    "sex_ensemble_test_proba = sex_ensemble.predict_proba(X_test_processed)[:, 1]\n",
    "adhd_ensemble_test_proba = adhd_ensemble.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# For females, blend with specialized model predictions\n",
    "sex_test_preds = (sex_test_proba >= 0.5).astype(int)\n",
    "female_test_indices = np.where(sex_test_preds == 1)[0]\n",
    "\n",
    "if len(female_test_indices) > 0:\n",
    "    female_test_subset = X_test_processed[female_test_indices]\n",
    "    female_adhd_test_proba = female_adhd_model.predict_proba(female_test_subset)[:, 1]\n",
    "    \n",
    "    # Blend predictions for females (70% specialized, 30% general)\n",
    "    adhd_test_proba_blended = adhd_test_proba.copy()\n",
    "    adhd_test_proba_blended[female_test_indices] = 0.3 * adhd_test_proba[female_test_indices] + 0.7 * female_adhd_test_proba\n",
    "else:\n",
    "    adhd_test_proba_blended = adhd_test_proba\n",
    "\n",
    "# Create final blended predictions\n",
    "final_sex_test_proba = 0.6 * sex_test_proba + 0.4 * sex_ensemble_test_proba\n",
    "final_adhd_test_proba = 0.5 * adhd_test_proba_blended + 0.5 * adhd_ensemble_test_proba\n",
    "\n",
    "final_sex_test_preds = (final_sex_test_proba >= sex_threshold).astype(int)\n",
    "final_adhd_test_preds = (final_adhd_test_proba >= adhd_threshold).astype(int)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'participant_id': test_data.index,\n",
    "    'ADHD_Outcome': final_adhd_test_preds,\n",
    "    'Sex_F': final_sex_test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created successfully!\")\n",
    "\n",
    "# 10. Feature importance analysis\n",
    "if hasattr(sex_model, 'feature_importances_'):\n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = []\n",
    "    for name, transformer, features in preprocessor.transformers_:\n",
    "        if name == 'num':\n",
    "            feature_names.extend(features)\n",
    "        elif name == 'cat':\n",
    "            ohe = transformer.named_steps['onehot']\n",
    "            if hasattr(ohe, 'get_feature_names_out'):\n",
    "                cat_features_transformed = ohe.get_feature_names_out(features)\n",
    "                feature_names.extend(cat_features_transformed)\n",
    "            else:\n",
    "                # Fallback for older scikit-learn versions\n",
    "                for cat in features:\n",
    "                    feature_names.append(f'{cat}_encoded')\n",
    "    \n",
    "    # Plot sex model feature importance\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sex_importance = sex_model.feature_importances_\n",
    "    if len(sex_importance) == len(feature_names):\n",
    "        sorted_idx = np.argsort(sex_importance)[-20:]\n",
    "        plt.barh(range(len(sorted_idx)), sex_importance[sorted_idx])\n",
    "        plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
    "        plt.title('Sex Model: Top 20 Feature Importances')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('sex_feature_importance.png')\n",
    "    \n",
    "    # Plot ADHD model feature importance\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    adhd_importance = adhd_model.feature_importances_\n",
    "    if len(adhd_importance) == len(feature_names):\n",
    "        sorted_idx = np.argsort(adhd_importance)[-20:]\n",
    "        plt.barh(range(len(sorted_idx)), adhd_importance[sorted_idx])\n",
    "        plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
    "        plt.title('ADHD Model: Top 20 Feature Importances')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('adhd_feature_importance.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b29754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
